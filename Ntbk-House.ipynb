{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# machine learning\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import  cross_val_score\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KagleScore(y_real, y_pred):\n",
    "    '''Kaggle usa RMS entre el log del valor\n",
    "    predicho y el real'''\n",
    "    yr = np.log(y_real)\n",
    "    yp = np.log(y_pred)\n",
    "    return np.sqrt( np.sum( (yr - yp) ** 2) / yr.shape[0] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#acquire data\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "combine = [train_df, test_df]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Data description in percentiles\n",
    "train_df.describe()\n",
    "#Distribution of categorical features\n",
    "train_df.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "contnum=list(train_df.select_dtypes(include=['int64','float64']))\n",
    "catfeat=list(train_df.select_dtypes(exclude=['int64','float64']))\n",
    "contnum.remove('SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Define columns to be used DEPRECATED\n",
    "contnum=['LotArea','BsmtFinSF1','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF','WoodDeckSF','OpenPorchSF','GarageArea']\n",
    "catfeat=['MSSubClass','MSZoning','Neighborhood','HouseStyle','ExterQual','ExterCond','HeatingQC','CentralAir','SaleCondition']\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Observe correlation continuous numerical features\n",
    "\n",
    "for feat in contnum:\n",
    "    train_df.plot(kind='scatter',x=feat,y='SalePrice')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Nouse\n",
    "contnum_nouse=['LotFrontage','BsmtFinSF2','LowQualFinSF','PoolArea','MasVnrArea']\n",
    "#for feat in contnum_nouse:\n",
    " #   train_df.plot(kind='scatter',x=feat,y='SalePrice')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Observe correlation categorical features\n",
    "#Analyze by pivoting features\n",
    "for feat in catfeat:\n",
    "    train_df[[feat, 'SalePrice']].groupby([feat], as_index=False).mean().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Check for Nan\n",
    "train_df[contnum].isnull().sum()\n",
    "train_df[catfeat].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Elimina de las listas de feats las que tengan mas de 5% de NaN\n",
    "join = pd.concat([train_df,test_df],axis=0)\n",
    "\n",
    "\n",
    "for tipo in [contnum,catfeat]:\n",
    "    lista=[]\n",
    "    for column in tipo:\n",
    "        if (join.isnull().sum()[column]>len(join[column].index)*.05):\n",
    "                lista.append(column)\n",
    "    \n",
    "    for item in lista:        tipo.remove(item)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Complete Nan for continuous feats with mean\n",
    "for dataset in combine:\n",
    "    for feat in contnum:\n",
    "        dataset[feat].fillna(value=dataset[feat].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Complete Nan for cat features with most common ocurrence\n",
    "for column in catfeat:\n",
    "    for dataset in combine:\n",
    "        freq_port=dataset[column].dropna().mode()[0]\n",
    "        dataset[column] = dataset[column].fillna(freq_port)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Encoding\n",
    "#encode catfeat labels\n",
    "#pd.concat([train_df[catfeat],test_df[catfeat]])\n",
    "\n",
    "\n",
    "for feat in catfeat:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(pd.concat([train_df[feat],test_df[feat]]))\n",
    "    for dataset in combine:\n",
    "            dataset[feat]=le.transform(dataset[feat])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fix para onehot encoding, encontrar manera de analizar train y test juntos\n",
    "\n",
    "train_df['HouseStyle'].replace(to_replace='2.5Fin',value='2.5Unf',inplace=True)\n",
    "test_df['MSSubClass'].replace(to_replace=150,value=40,inplace=True)\n",
    "\n",
    "#one hot encode Cat features\n",
    "train_df_dum = pd.get_dummies( train_df[catfeat] )\n",
    "test_df_dum = pd.get_dummies( test_df[catfeat] )\n",
    "\n",
    "\n",
    "# get the columns in train that are not in test\n",
    "col_to_add = np.setdiff1d(train_df_dum.columns, test_df_dum.columns)\n",
    "\n",
    "# add these columns to test, setting them equal to zero\n",
    "for c in col_to_add:\n",
    "    test_df_dum[c] = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training\n",
    "\n",
    "Deje solo RF, DT y SVM ya que son los que dan los score mas altos"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "X_train = pd.concat([train_df[contnum],train_df[catfeat]],axis=1) #\n",
    "Y_train = train_df['SalePrice']\n",
    "X_test  = pd.concat([test_df[contnum],test_df[catfeat]],axis=1) #\n",
    "X_train.shape,X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 249), (1459, 249))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.concat([train_df[contnum],train_df_dum],axis=1) #\n",
    "Y_train = train_df['SalePrice']\n",
    "X_test  = pd.concat([test_df[contnum],test_df_dum],axis=1) #\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "dt_old=DecisionTreeRegressor()\n",
    "dt_old.fit(X_train,Y_train)\n",
    "\n",
    "print '-Old accuracy-'\n",
    "acc_dt_old = dt_old.score(X_train, Y_train)\n",
    "acc_dt_old\n",
    "\n",
    "\n",
    "print '-Old CV score-'\n",
    "score_old = cross_val_score(dt_old,X_train,Y_train,cv=5)\n",
    "score_old.mean()\n",
    "\n",
    "# set of parameters to test\n",
    "parameters = {\"criterion\": [\"mse\", \"mae\"],\n",
    "              \"min_samples_split\": [2, 10, 20, 40],\n",
    "              \"max_depth\": [None, 2, 5, 10, 20],\n",
    "              \"min_samples_leaf\": [1, 5, 10],\n",
    "              \"max_leaf_nodes\": [None, 5, 10, 20],\n",
    "              }\n",
    "\n",
    "dt=DecisionTreeRegressor()\n",
    "grid_search = GridSearchCV(dt, parameters, cv=5)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "   \n",
    "print 'Best score: %0.3f' % grid_search.best_score_\n",
    "print 'Best parameters set:'\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print '\\t%s: %r' % (param_name, best_parameters[param_name])\n",
    "\n",
    "print '-new accuracy-'\n",
    "acc_dt = grid_search.score(X_train, Y_train)\n",
    "acc_dt \n",
    "\n",
    "predictions = grid_search.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059140436460601832"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get kaggle score:\n",
    "KagleScore(Y_train, grid_search.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Old accuracy-\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.96912292995869498"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Old CV score-\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84006752725012246"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=4, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [5, 10, 20, 50], 'criterion': ['mse', 'mae']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.855\n",
      "Best parameters set:\n",
      "\tcriterion: 'mae'\n",
      "\tn_estimators: 20\n",
      "-new accuracy-\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.97831545736906633"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_old=RandomForestRegressor()\n",
    "rf_old.fit(X_train,Y_train)\n",
    "\n",
    "print '-Old accuracy-'\n",
    "acc_rf_old = rf_old.score(X_train, Y_train)\n",
    "acc_rf_old\n",
    "\n",
    "\n",
    "print '-Old CV score-'\n",
    "score_old = cross_val_score(rf_old,X_train,Y_train,cv=5)\n",
    "score_old.mean()\n",
    "\n",
    "# set of parameters to test\n",
    "parameters = {\"criterion\": [\"mse\", \"mae\"],\n",
    "              \"n_estimators\": [5, 10, 20, 50], #Si pongo mas de 50 me cuelga la pc\n",
    "              #\"max_depth\": [None, 50], #Aumenta muchisimo el uso la memoria\n",
    "              #\"min_samples_split\": [1, 2, 3],\n",
    "              #\"min_samples_leaf\": [1, 2, 3]    \n",
    "             }\n",
    "\n",
    "dt=RandomForestRegressor(n_jobs=4)\n",
    "grid_search = GridSearchCV(dt, parameters, cv=5)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "   \n",
    "print 'Best score: %0.3f' % grid_search.best_score_\n",
    "print 'Best parameters set:'\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print '\\t%s: %r' % (param_name, best_parameters[param_name])\n",
    "\n",
    "print '-new accuracy-'\n",
    "acc_dt = grid_search.score(X_train, Y_train)\n",
    "acc_dt \n",
    "\n",
    "\n",
    "pred_RF = grid_search.predict(X_test)\n",
    "pred_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=50, n_jobs=4, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tuned RF\n",
    "rf=RandomForestRegressor(n_jobs=4,criterion='mse',n_estimators=50)\n",
    "rf.fit(X_train, Y_train)\n",
    "pred_RF = grid_search.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, Y_train)\n",
    "Y_pred_svc = svc.predict(X_test)\n",
    "acc_svc = round(svc.score(X_train, Y_train) * 100, 5)\n",
    "acc_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acc_random_forest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-59f8deebedf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m               'Decision Tree'],\n\u001b[1;32m      6\u001b[0m     'Score': [acc_svc, \n\u001b[0;32m----> 7\u001b[0;31m               \u001b[0macc_random_forest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m               acc_decision_tree]})\n\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'acc_random_forest' is not defined"
     ]
    }
   ],
   "source": [
    "#Model evaluation\n",
    "models = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines',  \n",
    "              'Random Forest', \n",
    "              'Decision Tree'],\n",
    "    'Score': [acc_svc, \n",
    "              acc_random_forest, \n",
    "              acc_decision_tree]})\n",
    "print models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"Id\": test_df[\"Id\"],\n",
    "        \"SalePrice\": pred_RF\n",
    "    })\n",
    "submission.to_csv('submissionrf284.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
